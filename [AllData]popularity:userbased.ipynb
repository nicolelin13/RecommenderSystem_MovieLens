{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "* Data load\n",
    "* Train/Test dataset splitting (for the evaluation part)\n",
    "* Data cleaning (if needed)\n",
    "\n",
    "There may be some other needsm, like listed below, when it comes to different algorithms. For popularity recommendation and collaborative recommendation, there is no need to merge data. For content-based recommendation, we need more information about movies to provide the similarity. For that part processing, it will be done later when it's needed. \n",
    "* Data integrating / transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(dataset):\n",
    "    with open(dataset) as file:\n",
    "        data = file.read().splitlines()\n",
    "    file.close()\n",
    "    columns = data[0].strip('\\n').split(\"\\t\")\n",
    "    rows = []\n",
    "    rows_num = len(data)\n",
    "    for i in range(1,rows_num):\n",
    "        row = [int(value) if value.isdigit() else float(value) if isfloat(value) else value \n",
    "               for value in data[i].strip('\\n').split(\"\\t\")]\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows,columns=columns)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another load function --  if there is any issue related with unicoding problem, use this function instead\n",
    "def load2(dataset):\n",
    "    with open(dataset,'rb') as file:\n",
    "        data = [l.decode('utf8', 'ignore') for l in file.readlines()]\n",
    "    file.close()\n",
    "    columns = data[0].strip('\\r\\n').split(\"\\t\")\n",
    "    rows = []\n",
    "    rows_num = len(data)\n",
    "    for i in range(1,rows_num):\n",
    "        #row = [int(value) if value.isdigit() else float(value) if isfloat(value) else value \n",
    "               #for value in data[i].strip('\\n').split(\"\\t\")]\n",
    "        row = [int(value) if value.isdigit() else float(value) if isfloat(value) else value \n",
    "               for value in data[i].strip('\\r\\n').split(\"\\t\")]\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows,columns=columns)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_basic_info(data):\n",
    "    print (\"The shape of dataset:\")\n",
    "    print (data.shape)\n",
    "    print (\"\\nAttribute names and types:\")\n",
    "    with pd.option_context('display.max_rows', None):\n",
    "        print (data.dtypes)\n",
    "    print (\"\\nAny missing values:\")\n",
    "    print (data.isnull().sum().sum())\n",
    "    \n",
    "    missing = pd.DataFrame(data.isnull().sum())\n",
    "    missing.columns = ['Missing count']\n",
    "    missing['Missing percentage'] = (missing['Missing count']/data.shape[0])*100\n",
    "    print (\"\\nAny missing values:\")\n",
    "    print (missing)\n",
    "    \n",
    "    print (\"\\nExample:\")\n",
    "    print(data.head(1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.17 s, sys: 592 ms, total: 8.76 s\n",
      "Wall time: 9.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "movies = load2('movies.dat')\n",
    "user_ratedmovies = load2(\"user_ratedmovies.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of dataset:\n",
      "(10197, 21)\n",
      "\n",
      "Attribute names and types:\n",
      "id                         int64\n",
      "title                     object\n",
      "imdbID                     int64\n",
      "spanishTitle              object\n",
      "imdbPictureURL            object\n",
      "year                       int64\n",
      "rtID                      object\n",
      "rtAllCriticsRating        object\n",
      "rtAllCriticsNumReviews    object\n",
      "rtAllCriticsNumFresh      object\n",
      "rtAllCriticsNumRotten     object\n",
      "rtAllCriticsScore         object\n",
      "rtTopCriticsRating        object\n",
      "rtTopCriticsNumReviews    object\n",
      "rtTopCriticsNumFresh      object\n",
      "rtTopCriticsNumRotten     object\n",
      "rtTopCriticsScore         object\n",
      "rtAudienceRating          object\n",
      "rtAudienceNumRatings      object\n",
      "rtAudienceScore           object\n",
      "rtPictureURL              object\n",
      "dtype: object\n",
      "\n",
      "Any missing values:\n",
      "0\n",
      "\n",
      "Any missing values:\n",
      "                        Missing count  Missing percentage\n",
      "id                                  0                 0.0\n",
      "title                               0                 0.0\n",
      "imdbID                              0                 0.0\n",
      "spanishTitle                        0                 0.0\n",
      "imdbPictureURL                      0                 0.0\n",
      "year                                0                 0.0\n",
      "rtID                                0                 0.0\n",
      "rtAllCriticsRating                  0                 0.0\n",
      "rtAllCriticsNumReviews              0                 0.0\n",
      "rtAllCriticsNumFresh                0                 0.0\n",
      "rtAllCriticsNumRotten               0                 0.0\n",
      "rtAllCriticsScore                   0                 0.0\n",
      "rtTopCriticsRating                  0                 0.0\n",
      "rtTopCriticsNumReviews              0                 0.0\n",
      "rtTopCriticsNumFresh                0                 0.0\n",
      "rtTopCriticsNumRotten               0                 0.0\n",
      "rtTopCriticsScore                   0                 0.0\n",
      "rtAudienceRating                    0                 0.0\n",
      "rtAudienceNumRatings                0                 0.0\n",
      "rtAudienceScore                     0                 0.0\n",
      "rtPictureURL                        0                 0.0\n",
      "\n",
      "Example:\n",
      "                                                                        0\n",
      "id                                                                      1\n",
      "title                                                           Toy story\n",
      "imdbID                                                             114709\n",
      "spanishTitle                                         Toy story (juguetes)\n",
      "imdbPictureURL          http://ia.media-imdb.com/images/M/MV5BMTMwNDU0...\n",
      "year                                                                 1995\n",
      "rtID                                                            toy_story\n",
      "rtAllCriticsRating                                                      9\n",
      "rtAllCriticsNumReviews                                                 73\n",
      "rtAllCriticsNumFresh                                                   73\n",
      "rtAllCriticsNumRotten                                                   0\n",
      "rtAllCriticsScore                                                     100\n",
      "rtTopCriticsRating                                                    8.5\n",
      "rtTopCriticsNumReviews                                                 17\n",
      "rtTopCriticsNumFresh                                                   17\n",
      "rtTopCriticsNumRotten                                                   0\n",
      "rtTopCriticsScore                                                     100\n",
      "rtAudienceRating                                                      3.7\n",
      "rtAudienceNumRatings                                               102338\n",
      "rtAudienceScore                                                        81\n",
      "rtPictureURL            http://content7.flixster.com/movie/10/93/63/10...\n"
     ]
    }
   ],
   "source": [
    "dataset_basic_info(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of dataset:\n",
      "(855598, 9)\n",
      "\n",
      "Attribute names and types:\n",
      "userID           int64\n",
      "movieID          int64\n",
      "rating         float64\n",
      "date_day         int64\n",
      "date_month       int64\n",
      "date_year        int64\n",
      "date_hour        int64\n",
      "date_minute      int64\n",
      "date_second      int64\n",
      "dtype: object\n",
      "\n",
      "Any missing values:\n",
      "0\n",
      "\n",
      "Any missing values:\n",
      "             Missing count  Missing percentage\n",
      "userID                   0                 0.0\n",
      "movieID                  0                 0.0\n",
      "rating                   0                 0.0\n",
      "date_day                 0                 0.0\n",
      "date_month               0                 0.0\n",
      "date_year                0                 0.0\n",
      "date_hour                0                 0.0\n",
      "date_minute              0                 0.0\n",
      "date_second              0                 0.0\n",
      "\n",
      "Example:\n",
      "                  0\n",
      "userID         75.0\n",
      "movieID         3.0\n",
      "rating          1.0\n",
      "date_day       29.0\n",
      "date_month     10.0\n",
      "date_year    2006.0\n",
      "date_hour      23.0\n",
      "date_minute    17.0\n",
      "date_second    16.0\n"
     ]
    }
   ],
   "source": [
    "dataset_basic_info(user_ratedmovies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set: 684478\n",
      "Size of test set: 171120\n"
     ]
    }
   ],
   "source": [
    "um_train_df, umtest_df = train_test_split(user_ratedmovies,\n",
    "                                          stratify=user_ratedmovies['userID'],\n",
    "                                          train_size=0.8, test_size=0.2, random_state=99)\n",
    "print (\"Size of train set: {}\\nSize of test set: {}\".format(um_train_df.shape[0],umtest_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Function \n",
    "These are functions needed whichever algorithms will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similarity for Collabrative item-based recommender \n",
    "\n",
    "def cosine(X, Y):\n",
    "    X_norm = (sum(map(lambda x:x*x, X)))**0.5\n",
    "    Y_norm = (sum(map(lambda y:y*y, Y)))**0.5\n",
    "    XdotY = sum(map(lambda x,y:x*y, X, Y))\n",
    "    cosine = XdotY/(X_norm*Y_norm)\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(orginal, predited):\n",
    "    '''orginal: the original user rating\n",
    "    predicted: new ratings based on prediction'''\n",
    "    original = np.array(orginal)\n",
    "    predicted = np.array(predited)\n",
    "    rmse = np.sqrt(((orginal - predited) ** 2).mean())\n",
    "    return rmse\n",
    "\n",
    "def MAE(original, predicted):\n",
    "    '''orginal: the original user rating\n",
    "    predicted: new ratings based on prediction'''\n",
    "    original = np.array(original)\n",
    "    predicted = np.array(predicted)\n",
    "    mae = sum(abs(original-predicted)).mean()\n",
    "    return mae\n",
    "\n",
    "def Evaluations(orginal, predited):\n",
    "    '''Function evaluations is created to compare the evaluation from different approaches\n",
    "    MAE: metric used in class\n",
    "    RMSE: metric used in Netflix challenging\n",
    "    '''\n",
    "    rmse = RMSE(orginal, predited)\n",
    "    mae = MAE(original, predicted)\n",
    "    return rmse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classes\n",
    "Classes stands for different recommendation approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Recommendation\n",
    "Recommend the most popular items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def popularity_table(user_ratedmovies):\n",
    "    table = user_ratedmovies.groupby('movieID')['rating'].agg(['mean','count']).sort_values(by=['mean','count'],ascending=False)\n",
    "    better_table = table.loc[table['count']>=100]\n",
    "    count_table = user_ratedmovies.groupby('movieID')['rating'].agg(['mean','count']).sort_values(by=['count','mean'],ascending=False)\n",
    "    return table, better_table, count_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "popularity_df, better_popularity_df, count_popularity_df = popularity_table(um_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47117</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7447</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7699</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8659</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8936</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean  count\n",
       "movieID             \n",
       "47117     5.0      2\n",
       "320       5.0      1\n",
       "404       5.0      1\n",
       "701       5.0      1\n",
       "1098      5.0      1\n",
       "1575      5.0      1\n",
       "1819      5.0      1\n",
       "2063      5.0      1\n",
       "3630      5.0      1\n",
       "4044      5.0      1\n",
       "5194      5.0      1\n",
       "5203      5.0      1\n",
       "5552      5.0      1\n",
       "5626      5.0      1\n",
       "6146      5.0      1\n",
       "6913      5.0      1\n",
       "7447      5.0      1\n",
       "7699      5.0      1\n",
       "8659      5.0      1\n",
       "8936      5.0      1"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularity_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>4.369110</td>\n",
       "      <td>1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>4.323831</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4.289779</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44555</th>\n",
       "      <td>4.275424</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>4.249304</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>4.249126</td>\n",
       "      <td>1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4.248172</td>\n",
       "      <td>1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>4.246114</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>4.245543</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4.241742</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58559</th>\n",
       "      <td>4.236782</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>4.234127</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>4.218310</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016</th>\n",
       "      <td>4.216287</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>4.210383</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>4.190184</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>4.188984</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>4.185328</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>4.182171</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>4.177471</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean  count\n",
       "movieID                 \n",
       "318      4.369110   1146\n",
       "858      4.323831    877\n",
       "50       4.289779    949\n",
       "44555    4.275424    236\n",
       "1203     4.249304    359\n",
       "2959     4.249126   1144\n",
       "296      4.248172   1231\n",
       "3435     4.246114    193\n",
       "912      4.245543    617\n",
       "750      4.241742    666\n",
       "58559    4.236782    435\n",
       "926      4.234127    126\n",
       "1221     4.218310    710\n",
       "6016     4.216287    571\n",
       "2019     4.210383    366\n",
       "3462     4.190184    163\n",
       "4226     4.188984   1053\n",
       "1193     4.185328    777\n",
       "3030     4.182171    129\n",
       "4973     4.177471    941"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_popularity_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>4.164906</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>3.927835</td>\n",
       "      <td>1261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>4.083533</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4.248172</td>\n",
       "      <td>1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5952</th>\n",
       "      <td>4.019024</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7153</th>\n",
       "      <td>4.089916</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>4.113946</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>4.062608</td>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>4.369110</td>\n",
       "      <td>1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>4.249126</td>\n",
       "      <td>1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>3.457746</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>3.800802</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>3.990608</td>\n",
       "      <td>1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>4.068058</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>3.858525</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>3.044907</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>4.103914</td>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>3.471884</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>4.188984</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3578</th>\n",
       "      <td>3.844646</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean  count\n",
       "movieID                 \n",
       "2571     4.164906   1325\n",
       "356      3.927835   1261\n",
       "4993     4.083533   1251\n",
       "296      4.248172   1231\n",
       "5952     4.019024   1209\n",
       "7153     4.089916   1190\n",
       "2858     4.113946   1176\n",
       "593      4.062608   1158\n",
       "318      4.369110   1146\n",
       "2959     4.249126   1144\n",
       "480      3.457746   1136\n",
       "4306     3.800802   1122\n",
       "2762     3.990608   1118\n",
       "260      4.068058   1102\n",
       "1270     3.858525   1085\n",
       "780      3.044907   1080\n",
       "1196     4.103914   1073\n",
       "1580     3.471884   1067\n",
       "4226     4.188984   1053\n",
       "3578     3.844646   1046"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_popularity_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    '''popularity-based recommendation algorithm: \n",
    "    Given a user U and an item I, \n",
    "    compute the predicted rating of U on I as \n",
    "    the mean rating for I among all users who have rated I.\n",
    "    In other words, this method is to recommend most popular movies that the user hasn't watched'''\n",
    "    \n",
    "    model_name= 'Popularity'\n",
    "    \n",
    "    def __init__(self, movie_df, popularity_kind):\n",
    "        ''':param: \n",
    "        movie_df: the movie information table, at least include movieID and movieName\n",
    "        \n",
    "        popularity_kind: Based on different defination of \"popularity\",diffferent tables are used\n",
    "        1: popularity means the highest mean value, secondary consideration is count value (how many people rated the movie),\n",
    "        2: popularity based on the description in \"1\", but add 100 as count threshold\n",
    "        3: popularity means most people rated the movie, secondary consideration is the mean rating of the movie\n",
    "        '''\n",
    "        self.popularity_kind = popularity_kind\n",
    "        self.moviedf = movie_df\n",
    "    \n",
    "    \n",
    "    def get_model_name(self):\n",
    "        return self.model_name\n",
    "            \n",
    "    \n",
    "    def fit(self, user_ratedmovies_df):\n",
    "        '''Fit for this approach is to create the popularity table\n",
    "        Fit with training dataset\n",
    "        \n",
    "        Based on different defination of \"popularity\",\n",
    "        diffferent tables are used\n",
    "        \n",
    "        :param: \n",
    "        user_ratedmovies_df: whole user_ratedmoives dataset\n",
    "        \n",
    "        :output: the popularity table based on different popularity defination'''\n",
    "        \n",
    "        self.umdf = user_ratedmovies_df\n",
    "        self.ptable_overall = self.umdf.groupby('movieID')['rating'].agg(['mean','count']).sort_values(by=['mean','count'],\n",
    "                                                                                                       ascending=False)\n",
    "        \n",
    "        if self.popularity_kind == 1:\n",
    "            self.ptable = self.ptable_overall\n",
    "        \n",
    "        elif self.popularity_kind == 2:\n",
    "            self.ptable = self.ptable_overall.loc[self.ptable_overall['count']>=100]\n",
    "        \n",
    "        elif self.popularity_kind == 3:\n",
    "            self.ptable = self.umdf.groupby('movieID')['rating'].agg(['mean','count']).sort_values(by=['count','mean'],\n",
    "                                                                                                   ascending=False)\n",
    "        else:\n",
    "            print(\"Error: popularity_kind not exist.\")\n",
    "    \n",
    "    \n",
    "    def predict(self, data_topredict):\n",
    "        '''Prediction unknown data (test dataset)\n",
    "        \n",
    "        :param: a dataset including userID and movieID\n",
    "        \n",
    "        :return: the list of movie ratings, same order as the input\n",
    "        '''\n",
    "        movie_predict_list  = data_topredict['movieID'].tolist()\n",
    "        popularity_predict_list = [self.ptable_overall.ix[movie]['mean'] \n",
    "                                   for movie in movie_predict_list]\n",
    "        return popularity_predict_list\n",
    "\n",
    "    \n",
    "    def recommend(self, userIDlist, topn=20):\n",
    "        '''Print the recommendations out'''\n",
    "        recommend_id = []\n",
    "        recommend_name = []\n",
    "        \n",
    "        users = self.umdf['userID'].unique().tolist()\n",
    "        \n",
    "        for user in userIDlist:\n",
    "            if user in users:\n",
    "                user_table = self.umdf.loc[self.umdf['userID']==user]\n",
    "                movies_watched = user_table['movieID'].tolist()\n",
    "            else:\n",
    "            # if the user not exit in the known datset, it's taken as new user, the watchlist is none\n",
    "                movies_watched = []\n",
    "            new_table = self.ptable.reset_index()\n",
    "            recommend_movie_list = new_table[~new_table['movieID'].isin(movies_watched)]['movieID'].head(topn).tolist()\n",
    "            recommend_movie_list_name = [self.moviedf.loc[self.moviedf['id']==movie]['title'] \n",
    "                                         for movie in recommend_movie_list]\n",
    "            recommend_id.append(recommend_movie_list)\n",
    "            recommend_name.append(recommend_movie_list_name)\n",
    "        \n",
    "        recommend_out = {'userID':userIDlist,\n",
    "                         'recommend_movieID':recommend_id,\n",
    "                         'recommend_movieName':recommend_name}\n",
    "        \n",
    "        recommend_df = pd.DataFrame(recommend_out)\n",
    "        recommend_df.set_index('userID', inplace=True)\n",
    "        \n",
    "        return recommend_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_model = PopularityRecommender(movies,popularity_kind=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Popularity'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "popularity_model.get_model_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 144 ms, sys: 68.2 ms, total: 212 ms\n",
      "Wall time: 222 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "popularity_model.fit(user_ratedmovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Queena/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:65: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 s, sys: 471 ms, total: 36.1 s\n",
      "Wall time: 38.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "popularity_model_predict = popularity_model.predict(umtest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80.7 ms, sys: 8.88 ms, total: 89.6 ms\n",
      "Wall time: 90.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_list = [75, 78, 71534]\n",
    "popularity_model_recommend = popularity_model.recommend(user_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Recommendation\n",
    "Simiarity measurement: Pearson Correlation (works well based on rating); Manhattan distance, Euclidean distance, Cosine similarity\n",
    "\n",
    "User-based collaborative -- pearson correlation\n",
    "Recommendations based on ratings from other (similar) users\n",
    "\n",
    "Item-based collaborative -- cosine similarity (prediction of item I for user a is based on the past ratings of user a on items similar to i)\n",
    "Recommendations based on (similar) contents -- in this case, movies. \n",
    "\n",
    "DOESN'T REQUIRE ANY INFO ABOUT ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeRecommender:\n",
    "    model_name = \"Collaborative\"\n",
    "\n",
    "    def __init__(self, base, movie_df, user_ratedmovies):\n",
    "        \"\"\":param:\n",
    "        base: which collaborative recommender used\n",
    "        base = 1: user-based collaborative\n",
    "        base = 2: item-based collaborative\n",
    "        base = 3: combination of user_based and iten_based collaborative\n",
    "\n",
    "        movie_df: the movie information table, at least include movieID and movieName\n",
    "\n",
    "        user_ratedmovies: whole user_ratedmoives dataset\n",
    "        \"\"\"\n",
    "        self.base = base\n",
    "        self.moviedf = movie_df\n",
    "        self.umdf = user_ratedmovies\n",
    "\n",
    "    def get_model_name(self):\n",
    "        if self.base == 1:\n",
    "            b_name = \"User-based\"\n",
    "        elif self.base == 2:\n",
    "            b_name = \"Item-based\"\n",
    "        elif self.base == 3:\n",
    "            b_name = \"User-based and Item-based Combined\"\n",
    "        else:\n",
    "            b_name = \"\"\n",
    "        name = b_name + ' ' + self.model_name\n",
    "        return name\n",
    "\n",
    "    def create_table(self):\n",
    "        movie_list = self.moviedf['id'].tolist()\n",
    "        user_list = self.umdf['userID'].unique().tolist()\n",
    "        table = pd.DataFrame(np.nan, index=user_list, columns=movie_list)\n",
    "\n",
    "        user_ratings_num = self.umdf.shape[0]\n",
    "        for i in range(user_ratings_num):\n",
    "            user_info = self.umdf.iloc[i]\n",
    "            user_info_id = user_info['userID']\n",
    "            user_info_movie = user_info['movieID']\n",
    "            user_info_rating = user_info['rating']\n",
    "            table.loc[user_info_id, user_info_movie] = user_info_rating\n",
    "\n",
    "        user_item_table = table\n",
    "        term_user_table = table.T\n",
    "\n",
    "        return user_item_table, term_user_table\n",
    "\n",
    "    def fit(self, user_item_table, term_user_table):\n",
    "        \"\"\"process to create the similarity matrix\n",
    "        :output: the similarity matrix\"\"\"\n",
    "\n",
    "        self.user_item_table = user_item_table\n",
    "        self.term_user_table = term_user_table\n",
    "\n",
    "        if self.base == 1:  # similarity for users -- pearson correlation\n",
    "            index_list = self.user_item_table.index.values.tolist()\n",
    "            similarity_table = pd.DataFrame(0.0, index=index_list, columns=index_list)\n",
    "            for user in index_list:\n",
    "                user_info = self.user_item_table.loc[user]\n",
    "                other_users = index_list[:]\n",
    "                other_users.remove(user)\n",
    "                for other_user in other_users:\n",
    "                    other_user_info = self.user_item_table.loc[other_user]\n",
    "                    nas = np.logical_or(np.isnan(user_info), np.isnan(other_user_info))\n",
    "                    corr = pearsonr(user_info[~nas], other_user_info[~nas])\n",
    "                    similarity_table.loc[user, other_user] = corr[0]\n",
    "\n",
    "        elif self.base == 2:  # similarity for items -- cosine similarity\n",
    "            index_list = self.term_user_table.index.values.tolist()\n",
    "            similarity_table = pd.DataFrame(0.0, index=index_list, columns=index_list)\n",
    "            for movie in index_list:\n",
    "                movie_info = self.term_user_table.loc[movie]\n",
    "                other_movies = index_list[:]\n",
    "                other_movies.remove(movie)\n",
    "                for other_movie in other_movies:\n",
    "                    other_movie_info = self.term_user_table.loc[other_movie]\n",
    "                    nas = np.logical_or(np.isnan(movie_info), np.isnan(other_movie_info))\n",
    "                    if len(movie_info[~nas]) == 0 or len(movie_info[~nas]) == 0:\n",
    "                        cosin = 0\n",
    "                    else:\n",
    "                        cosin = cosine_similarity(movie_info[~nas], other_movie_info[~nas]).item(0)\n",
    "                    similarity_table.loc[movie, other_movie] = cosin\n",
    "\n",
    "        elif self.base == 3:\n",
    "            similarity_algorithms = ['user_based', 'item_based']\n",
    "            similarity_table_dict = {}\n",
    "            for algorithm in similarity_algorithms:\n",
    "                if algorithm == 'user_based':\n",
    "                    index_list = self.user_item_table.index.values.tolist()\n",
    "                    similarity_table = pd.DataFrame(0.0, index=index_list, columns=index_list)\n",
    "                    for user in index_list:\n",
    "                        user_info = self.user_item_table.loc[user]\n",
    "                        other_users = index_list[:]\n",
    "                        other_users.remove(user)\n",
    "                        for other_user in other_users:\n",
    "                            other_user_info = self.user_item_table.loc[other_user]\n",
    "                            nas = np.logical_or(np.isnan(user_info), np.isnan(other_user_info))\n",
    "                            corr = pearsonr(user_info[~nas], other_user_info[~nas])\n",
    "                            similarity_table.loc[user, other_user] = corr[0]\n",
    "                    similarity_table_dict[algorithm] = similarity_table\n",
    "                else:\n",
    "                    index_list = self.term_user_table.index.values.tolist()\n",
    "                    similarity_table = pd.DataFrame(0.0, index=index_list, columns=index_list)\n",
    "                    for movie in index_list:\n",
    "                        movie_info = self.term_user_table.loc[movie]\n",
    "                        other_movies = index_list[:]\n",
    "                        other_movies.remove(movie)\n",
    "                        for other_movie in other_movies:\n",
    "                            other_movie_info = self.term_user_table.loc[other_movie]\n",
    "                            nas = np.logical_or(np.isnan(movie_info), np.isnan(other_movie_info))\n",
    "                            if len(movie_info[~nas]) == 0 or len(movie_info[~nas]) == 0:\n",
    "                                cosin = 0\n",
    "                            else:\n",
    "                                cosin = cosine_similarity(movie_info[~nas], other_movie_info[~nas]).item(0)\n",
    "                            similarity_table.loc[movie, other_movie] = cosin\n",
    "                    similarity_table_dict[algorithm] = similarity_table\n",
    "            # even though the output for the base 3 is a dictionary\n",
    "            # to keep it consistant with base 1 and 2, the dictionary is assigned to same name object \"similarity_table\"\n",
    "            similarity_table = similarity_table_dict\n",
    "\n",
    "        else:\n",
    "            print(\"Error: the base selection is not available.\")\n",
    "\n",
    "        self.similarity_table = similarity_table\n",
    "\n",
    "    def predict(self, data_topredict, topn=20):\n",
    "        \"\"\"Prediction unknown data (test dataset)\n",
    "        :param:\n",
    "        data_topredict: a dataset including userID and movieID\n",
    "        topn: the top n most similar objects\n",
    "        :return:\n",
    "        the list of movie ratings, same order as the input\"\"\"\n",
    "\n",
    "        predict_num = data_topredict.shape[0]\n",
    "        output = []\n",
    "\n",
    "        if self.base == 1:\n",
    "            for num in range(predict_num):\n",
    "                movie_id = data_topredict.iloc[num]['movieID']\n",
    "                user_id = data_topredict.iloc[num]['userID']\n",
    "                similarity_to_user = self.similarity_table.sort_values(by=user_id, ascending=False).index.values\n",
    "\n",
    "                n = 1\n",
    "                i = 0\n",
    "                ratings = 0\n",
    "                while n <= topn:\n",
    "                    try:\n",
    "                        similar_user_id = similarity_to_user[i]\n",
    "                        similar_user_rating = self.user_item_table.loc[similar_user_id, movie_id]\n",
    "                        i += 1\n",
    "                        if similar_user_rating > 0:\n",
    "                            ratings += similar_user_rating\n",
    "                            n += 1\n",
    "                    except IndexError:\n",
    "                        n = n-1\n",
    "                        break\n",
    "                rating = ratings / n\n",
    "                output.append(rating)\n",
    "\n",
    "        elif self.base == 2:\n",
    "            for num in range(predict_num):\n",
    "                movie_id = data_topredict.iloc[num]['movieID']\n",
    "                user_id = data_topredict.iloc[num]['userID']\n",
    "                similarity_to_movie = self.similarity_table.sort_values(by=movie_id, ascending=False).index.values\n",
    "\n",
    "                n = 1\n",
    "                i = 0\n",
    "                ratings = 0\n",
    "                while n <= topn:\n",
    "                    try:\n",
    "                        similar_movie_id = similarity_to_movie[i]\n",
    "                        similar_movie_rating = self.term_user_table.loc[similar_movie_id, user_id]\n",
    "                        i += 1\n",
    "                        if similar_movie_rating > 0:\n",
    "                            ratings += similar_movie_rating\n",
    "                            n += 1\n",
    "                    except IndexError:\n",
    "                        n = n-1\n",
    "                        break\n",
    "                rating = ratings / n\n",
    "                output.append(rating)\n",
    "\n",
    "        elif self.base == 3:\n",
    "            similarity_algorithms = ['user_based', 'item_based']\n",
    "            output_dict = {key: [] for key in similarity_algorithms}\n",
    "            for algorithm in similarity_algorithms:\n",
    "                if algorithm == 'user_based':\n",
    "                    output = output_dict[algorithm]\n",
    "                    for num in range(predict_num):\n",
    "                        similarity_table = self.similarity_table[algorithm]\n",
    "                        movie_id = data_topredict.iloc[num]['movieID']\n",
    "                        user_id = data_topredict.iloc[num]['userID']\n",
    "                        similarity_to_user = similarity_table.sort_values(by=user_id, ascending=False).index.values\n",
    "\n",
    "                        n = 1\n",
    "                        i = 0\n",
    "                        ratings = 0\n",
    "                        while n <= topn:\n",
    "                            try:\n",
    "                                similar_user_id = similarity_to_user[i]\n",
    "                                similar_user_rating = self.user_item_table.loc[similar_user_id, movie_id]\n",
    "                                i += 1\n",
    "                                if similar_user_rating > 0:\n",
    "                                    ratings += similar_user_rating\n",
    "                                    n += 1\n",
    "                            except IndexError:\n",
    "                                n = n-1\n",
    "                                break\n",
    "                        rating = ratings / n\n",
    "                        output.append(rating)\n",
    "                    output_dict[algorithm] = output\n",
    "                else:\n",
    "                    output = output_dict[algorithm]\n",
    "                    for num in range(predict_num):\n",
    "                        similarity_table = self.similarity_table[algorithm]\n",
    "                        movie_id = data_topredict.iloc[num]['movieID']\n",
    "                        user_id = data_topredict.iloc[num]['userID']\n",
    "                        similarity_to_movie = similarity_table.sort_values(by=movie_id, ascending=False).index.values\n",
    "\n",
    "                        n = 1\n",
    "                        i = 0\n",
    "                        ratings = 0\n",
    "                        while n <= topn:\n",
    "                            try:\n",
    "                                similar_movie_id = similarity_to_movie[i]\n",
    "                                similar_movie_rating = self.term_user_table.loc[similar_movie_id, user_id]\n",
    "                                i += 1\n",
    "                                if similar_movie_rating > 0:\n",
    "                                    ratings += similar_movie_rating\n",
    "                                    n += 1\n",
    "                            except IndexError:\n",
    "                                n = n-1\n",
    "                                break\n",
    "                        rating = ratings / n\n",
    "                        output.append(rating)\n",
    "                    output_dict[algorithm] = output\n",
    "\n",
    "            output1_array = np.array(output_dict['user_based'])\n",
    "            output2_array = np.array(output_dict['item_based'])\n",
    "            output = list(0.5 * output1_array + 0.5 * output2_array)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def recommend(self, useridlist, topn_similarity=20, topn_recommends=20):\n",
    "        \"\"\"Print the recommendations out\n",
    "\n",
    "        :param:\n",
    "        userIDlist: list of users needing recommendation\n",
    "        topn: the top n recommendations for the user\n",
    "\n",
    "        :output:\n",
    "        return a dataframe including userID,\n",
    "        recommended movie id list,\n",
    "        recommended movie name list\n",
    "        \"\"\"\n",
    "        recommend_id = []\n",
    "        recommend_name = []\n",
    "\n",
    "        users = self.umdf['userID'].unique().tolist()\n",
    "        movies = set(self.umdf['movieID'].unique())\n",
    "\n",
    "        if self.base == 1:\n",
    "            for user in useridlist:\n",
    "                if user in users:\n",
    "                    user_table = self.umdf.loc[self.umdf['userID'] == user]\n",
    "                    movies_watched = set(user_table['movieID'])\n",
    "                else:\n",
    "                    movies_watched = set()\n",
    "                movies_to_predict_id = list(movies - movies_watched)\n",
    "\n",
    "                movies_to_predict_rating = []\n",
    "\n",
    "                for movie in movies_to_predict_id:\n",
    "                    similarity_to_user = self.similarity_table.sort_values(by=user, ascending=False).index.values\n",
    "                    n = 1\n",
    "                    i = 0\n",
    "                    ratings = 0\n",
    "                    while n <= topn_similarity:\n",
    "                        try:\n",
    "                            similar_user_id = similarity_to_user[i]\n",
    "                            similar_user_rating = self.user_item_table.loc[similar_user_id, movie]\n",
    "                            i += 1\n",
    "                            if similar_user_rating > 0:\n",
    "                                ratings += similar_user_rating\n",
    "                                n += 1\n",
    "                        except IndexError:\n",
    "                            n = n-1\n",
    "                            break\n",
    "                    rating = ratings / n\n",
    "                    movies_to_predict_rating.append(rating)\n",
    "\n",
    "                topn_movies_index = sorted(range(len(movies_to_predict_rating)),\n",
    "                                           key=lambda mi: movies_to_predict_rating[mi], reverse=True)[:topn_recommends]\n",
    "                topn_movies_id = [movies_to_predict_id[index] for index in topn_movies_index]\n",
    "                topn_movies_name = [self.moviedf.loc[self.moviedf['id'] == movie]['title']\n",
    "                                    for movie in topn_movies_id]\n",
    "                recommend_id.append(topn_movies_id)\n",
    "                recommend_name.append(topn_movies_name)\n",
    "\n",
    "        elif self.base == 2:\n",
    "            for user in useridlist:\n",
    "                if user in users:\n",
    "                    user_table = self.umdf.loc[self.umdf['userID'] == user]\n",
    "                    movies_watched = set(user_table['movieID'])\n",
    "                else:\n",
    "                    movies_watched = set()\n",
    "                movies_to_predict_id = list(movies - movies_watched)\n",
    "\n",
    "                movies_to_predict_rating = []\n",
    "\n",
    "                for movie in movies_to_predict_id:\n",
    "                    similarity_to_movie = self.similarity_table.sort_values(by=movie, ascending=False).index.values\n",
    "                    n = 1\n",
    "                    i = 0\n",
    "                    ratings = 0\n",
    "                    while n <= topn_similarity:\n",
    "                        try:\n",
    "                            similar_movie_id = similarity_to_movie[i]\n",
    "                            similar_movie_rating = self.item_user_table.loc[similar_movie_id, user]\n",
    "                            i += 1\n",
    "                            if similar_movie_rating > 0:\n",
    "                                ratings += similar_movie_rating\n",
    "                                n += 1\n",
    "                        except IndexError:\n",
    "                            n = n-1\n",
    "                            break\n",
    "                    rating = ratings / n\n",
    "                    movies_to_predict_rating.append(rating)\n",
    "\n",
    "                topn_movies_index = sorted(range(len(movies_to_predict_rating)),\n",
    "                                           key=lambda mi: movies_to_predict_rating[mi], reverse=True)[:topn_recommends]\n",
    "                topn_movies_id = [movies_to_predict_id[index] for index in topn_movies_index]\n",
    "                topn_movies_name = [self.moviedf.loc[self.moviedf['id'] == movie]['title']\n",
    "                                    for movie in topn_movies_id]\n",
    "                recommend_id.append(topn_movies_id)\n",
    "                recommend_name.append(topn_movies_name)\n",
    "\n",
    "        elif self.base == 3:\n",
    "            similarity_algorithms = ['user_based', 'item_based']\n",
    "\n",
    "            for user in useridlist:\n",
    "                if user in users:\n",
    "                    user_table = self.umdf.loc[self.umdf['userID'] == user]\n",
    "                    movies_watched = set(user_table['movieID'])\n",
    "                else:\n",
    "                    movies_watched = set()\n",
    "                movies_to_predict_id = list(movies - movies_watched)\n",
    "\n",
    "                movies_to_predict_rating_dict = {key: [] for key in similarity_algorithms}\n",
    "\n",
    "                for algorithm in similarity_algorithms:\n",
    "                    if algorithm == 'user_based':\n",
    "                        movies_to_predict_rating_user = movies_to_predict_rating_dict[algorithm]\n",
    "                        similarity_table = self.similarity_table[algorithm]\n",
    "\n",
    "                        for movie in movies_to_predict_id:\n",
    "                            similarity_to_user = similarity_table.sort_values(by=user, ascending=False).index.values\n",
    "                            \n",
    "                            n = 1\n",
    "                            i = 0\n",
    "                            ratings = 0\n",
    "                            while n <= topn_similarity:\n",
    "                                try:\n",
    "                                    similar_user_id = similarity_to_user[i]\n",
    "                                    similar_user_rating = self.user_item_table.loc[similar_user_id, movie]\n",
    "                                    i += 1\n",
    "                                    if similar_user_rating > 0:\n",
    "                                        ratings += similar_user_rating\n",
    "                                        n += 1\n",
    "                                except IndexError:\n",
    "                                    n = n-1\n",
    "                                    break\n",
    "                            rating = ratings / n\n",
    "                            movies_to_predict_rating_user.append(rating)\n",
    "\n",
    "                        movies_to_predict_rating_dict[algorithm] = movies_to_predict_rating_user\n",
    "\n",
    "                    else:\n",
    "                        movies_to_predict_rating_item = movies_to_predict_rating_dict[algorithm]\n",
    "                        similarity_table = self.similarity_table[algorithm]\n",
    "\n",
    "                        for movie in movies_to_predict_id:\n",
    "                            similarity_to_movie = similarity_table.sort_values(by=movie, ascending=False).index.values\n",
    "                            n = 1\n",
    "                            i = 0\n",
    "                            ratings = 0\n",
    "                            while n <= topn_similarity:\n",
    "                                try:\n",
    "                                    similar_movie_id = similarity_to_movie[i]\n",
    "                                    similar_movie_rating = self.item_user_table.loc[similar_movie_id, user]\n",
    "                                    i += 1\n",
    "                                    if similar_movie_rating > 0:\n",
    "                                        ratings += similar_movie_rating\n",
    "                                        n += 1\n",
    "                                except IndexError:\n",
    "                                    n = n-1\n",
    "                                    break\n",
    "                            rating = ratings / n\n",
    "                            movies_to_predict_rating_item.append(rating)\n",
    "\n",
    "                        movies_to_predict_rating_dict[algorithm] = movies_to_predict_rating_item\n",
    "\n",
    "                movies_to_predict_rating1_array = np.array(movies_to_predict_rating_dict['user_based'])\n",
    "                movies_to_predict_rating2_array = np.array(movies_to_predict_rating_dict['item_based'])\n",
    "                movies_to_predict_rating = list(movies_to_predict_rating1_array * 0.5 + movies_to_predict_rating2_array * 0.5)\n",
    "\n",
    "                topn_movies_index = sorted(range(len(movies_to_predict_rating)),\n",
    "                                           key=lambda mi: movies_to_predict_rating[mi], reverse=True)[:topn_recommends]\n",
    "                topn_movies_id = [movies_to_predict_id[index] for index in topn_movies_index]\n",
    "                topn_movies_name = [self.moviedf.loc[self.moviedf['id'] == movie]['title']\n",
    "                                    for movie in topn_movies_id]\n",
    "                recommend_id.append(topn_movies_id)\n",
    "                recommend_name.append(topn_movies_name)\n",
    "\n",
    "        recommend_out = {'userID': useridlist,\n",
    "                         'recommend_movieID': recommend_id,\n",
    "                         'recommend_movieName': recommend_name}\n",
    "\n",
    "        recommend_df = pd.DataFrame(recommend_out)\n",
    "        recommend_df.set_index('userID', inplace=True)\n",
    "\n",
    "        return recommend_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 µs, sys: 9 µs, total: 24 µs\n",
      "Wall time: 30 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "collaborativemodel_user = CollaborativeRecommender(base=1,\n",
    "                                                  movie_df=movies,\n",
    "                                                  user_ratedmovies=user_ratedmovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 40s, sys: 2.12 s, total: 6min 42s\n",
      "Wall time: 6min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_item_table,item_user_table = collaborativemodel_user.create_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Queena/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2998: RuntimeWarning: Mean of empty slice.\n",
      "  mx = x.mean()\n",
      "/Users/Queena/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/Queena/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2999: RuntimeWarning: Mean of empty slice.\n",
      "  my = y.mean()\n",
      "/Users/Queena/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:3003: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 30min 17s, sys: 34.3 s, total: 1h 30min 52s\n",
      "Wall time: 1h 32min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "collaborativemodel_user.fit(user_item_table, item_user_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37min 49s, sys: 16min 55s, total: 54min 45s\n",
      "Wall time: 55min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "collaborativemodel_user_predict = collaborativemodel_user.predict(umtest_df, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 10s, sys: 2min 28s, total: 12min 39s\n",
      "Wall time: 12min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_list = [325, 71509]\n",
    "collaborativemodel_user_recommend = collaborativemodel_user.recommend(user_list,topn_similarity=20, topn_recommends=20)\n",
    "collaborativemodel_user_recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Collaborative_user_model_alldata.pickle\"\n",
    "with open(filename, \"wb\") as file:\n",
    "    pickle.dump(collaborativemodel_user,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
